{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Gyzk-79jakA"
   },
   "source": [
    "To train this agent, click _Runtime_ and press _Run all_. Make sure you've enabled a free Tesla T4 GPU!\n",
    "\n",
    "<div class=\"align-center\">\n",
    "<a href=\"https://github.com/openpipe/art\"><img src=\"https://github.com/openpipe/art/raw/main/assets/ART_pill.png\" height=\"50\"></a>\n",
    "<a href=\"https://discord.com/invite/dnseNZuQ\"><img src=\"https://github.com/openpipe/art/raw/main/assets/Discord_pill.png\" height=\"50\"></a>\n",
    "<a href=\"https://openpipe.ai/blog/art-e-mail-agent\"><img src=\"https://github.com/openpipe/art/raw/main/assets/ART_E_pill.png\" height=\"50\"></a>\n",
    "\n",
    "Questions? Join the Discord and ask away! For feature requests or to leave a star, visit our [GitHub](https://github.com/openpipe/art).\n",
    "\n",
    "</div>\n",
    "\n",
    "<a href=\"https://art.openpipe.ai/\"><img src=\"https://github.com/openpipe/art/raw/main/assets/Header_separator.png\" height=\"5\"></a>\n",
    "\n",
    "This notebook shows how to train a Qwen 2.5 3B model to play Codenames. It will demonstrate how to set up a multi-turn agent, how to train it, and how to evaluate it.\n",
    "\n",
    "Completions will be logged to OpenPipe, and metrics will be logged to Weights & Biases.\n",
    "\n",
    "You will learn how to construct an [agentic environment](#Environment), how to define a [rollout](#Rollout), and how to run a [training loop](#Loop).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ENVzXbV0R0cW",
    "outputId": "3fe3745f-d3eb-4df2-d440-8984d005ff03"
   },
   "outputs": [],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)\n",
    "\n",
    "import psutil\n",
    "\n",
    "ram_gb = psutil.virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('Not using a high-RAM runtime')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0MXGfxPjakD"
   },
   "source": [
    "### Installation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xA5ADGKPjakD"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!uv pip install openpipe-art==0.3.11.post3 \"gql<4\" --prerelease allow --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KL6KizZ5Q3js",
    "outputId": "6ad3293d-ab99-48ea-e400-f077b92d7036"
   },
   "outputs": [],
   "source": [
    "!uv pip install openpipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-UAxXzqEjakC"
   },
   "source": [
    "### Environment Variables\n",
    "\n",
    "Later on in the notebook, we'll be creating a model that can automatically logs metrics to Weights & Biases. In order to do so, you'll need to provide your Weights & Biases API key as an environment variable.\n",
    "\n",
    "You can also optionally initiate an OpenPipe client to report completions to a [dashboard](https://app.openpipe.ai) to get a feel for what the completions your model is generating look like, and how they change over time. Logging to OpenPipe is free, but is not required for training!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d_8E8Yj3jakC"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Optional - We need an OPENAI_API_KEY to run validation. This is optional, and we will skip validation if not provided\n",
    "OPENAI_API_KEY=\"\"\n",
    "if OPENAI_API_KEY:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "# Optional\n",
    "WANDB_API_KEY=\"\"\n",
    "if WANDB_API_KEY:\n",
    "    os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n",
    "\n",
    "# Optional\n",
    "OPENPIPE_API_KEY = \"\"\n",
    "if OPENPIPE_API_KEY:\n",
    "    os.environ[\"OPENPIPE_API_KEY\"] = OPENPIPE_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5n8N1uSjakD"
   },
   "source": [
    "# Agentic Environment\n",
    "\n",
    "<a name=\"Environment\"></a>\n",
    "\n",
    "ART allows your agent to learn by interacting with its environment. In this example, we'll create an environment in which the agent can play Codenames.\n",
    "\n",
    "Feel free to read as much or as little of this section's code as you'd like. The important thing to understand is that we're defining the rules of this agent's environment. In many cases, this will already be defined by the task you're trying to solve, but if you need to define a custom environment, this is how you do it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K9h-g67egOpy"
   },
   "outputs": [],
   "source": [
    "# Download the 400 original codenames words and a dictionary to ensure that the clue is not outside of this dictionary\n",
    "import requests\n",
    "\n",
    "codenames_words_path = \"https://raw.githubusercontent.com/OpenPipe/ART/refs/heads/main/examples/codenames/codenames_words.json\"\n",
    "dictionary_path = \"https://raw.githubusercontent.com/OpenPipe/ART/refs/heads/main/examples/codenames/dictionary.json\"\n",
    "CODENAMES_WORDS = requests.get(codenames_words_path).json()\n",
    "DICTIONARY = requests.get(dictionary_path).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "we0PhGpVoGmR"
   },
   "outputs": [],
   "source": [
    "# Basic imports to get us running\n",
    "# ───────────────────────────────  Imports  ────────────────────────────────\n",
    "import asyncio\n",
    "import copy\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import uuid\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "import art\n",
    "from openpipe.client import AsyncOpenPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jSlnMfuvoK0O"
   },
   "outputs": [],
   "source": [
    "# ───────────────────────────────  Config  ──────────────────────────────\n",
    "NUM_STEPS = 100\n",
    "NUM_GAMES_PER_STEP = 10\n",
    "NUM_ROLLOUTS_PER_GAME = 20\n",
    "# reduce all three above to 5 to run the example quickly\n",
    "\n",
    "MODEL_NAME = \"codenames_model_op_5\"\n",
    "BASE_MODEL_NAME = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "VAL_BENCHMARK_MODEL = \"gpt-4.1-nano\"\n",
    "NUM_VALIDATION_GAMES = 50\n",
    "LEARNING_RATE = 5e-6\n",
    "BETA = 0.0\n",
    "DEBUG = False\n",
    "\n",
    "# — reward constants —\n",
    "# The following is the weightage for different kinds of outcomes from a game, to determine the reward\n",
    "MARGIN_REWARD_DICT = {\n",
    "    \"turn_limit\": -100,  # if the game reaches the turn limit for some reason, the team gets this penalty\n",
    "    \"error\": -100,  # if the game ends in an error, the team player that caused the error gets this penalty (e.g. spymaster gets this penalty if the clue is invalid)\n",
    "    \"assassin\": -30,  # if the team guesses the assassin, they get this penalty (both spymaster and operative get the penalty, since it could be an issue with the spymaster's clue or the operative's guess)\n",
    "    \"num_words_multiplier\": 10,  # the team gets this reward for each word they guess (fraction of words they guess correctly * num_words_multiplier)\n",
    "    \"margin_multiplier\": 1,  # the team gets this reward for however many words they defeat the other team by (difference in the number of words * margin_multiplier) (the losing team gets the negative of this)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_YTBUEFepm_J"
   },
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "\n",
    "\n",
    "# ────────────────────────  1. Utility helpers  ────────────────────────────\n",
    "async def call_llm(\n",
    "    model: art.Model,\n",
    "    messages: List[Dict[str, str]],\n",
    "    temperature: float = 0.7,\n",
    "    max_tokens: int = 500,\n",
    "    num_retries: int = 3,\n",
    "):\n",
    "    \"\"\"\n",
    "    Minimal, retry‑aware wrapper around `chat.completions.create`.\n",
    "    \"\"\"\n",
    "    for attempt in range(num_retries):\n",
    "        try:\n",
    "            client = AsyncOpenAI(\n",
    "                base_url=model.inference_base_url,\n",
    "                api_key=model.inference_api_key,\n",
    "            )\n",
    "            resp = await client.chat.completions.create(\n",
    "                model=model.name,\n",
    "                messages=messages,\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens,\n",
    "                logprobs=True,\n",
    "                store=False,\n",
    "            )\n",
    "            if not resp:\n",
    "                raise RuntimeError(\"empty response\")\n",
    "            return resp\n",
    "        except Exception as e:\n",
    "            print(f\"LLM error ({attempt + 1}/{num_retries}): {e}\")\n",
    "            await asyncio.sleep(1)\n",
    "    raise RuntimeError(\"LLM call failed after retries\")\n",
    "\n",
    "\n",
    "# ───────────────────────  2. Core game classes  ───────────────────────────\n",
    "class Card:\n",
    "    \"\"\"\n",
    "    One word on the Codenames board.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, word: str, color: str):\n",
    "        self.word = word\n",
    "        self.color = color  # blue | red | neutral | assassin\n",
    "        self.revealed = False\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.word}{'(X)' if self.revealed else ''}:{self.color}\"\n",
    "\n",
    "\n",
    "class GameState:\n",
    "    \"\"\"\n",
    "    Full mutable game state with an event log.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        cards: List[Card],\n",
    "        starting_team: str = \"blue\",\n",
    "        game_id: int = 0,\n",
    "    ):\n",
    "        self.cards = cards\n",
    "        self.current_team = starting_team\n",
    "        self.words_left = {\n",
    "            \"blue\": sum(1 for c in cards if c.color == \"blue\"),\n",
    "            \"red\": sum(1 for c in cards if c.color == \"red\"),\n",
    "        }\n",
    "        self.starting_team = starting_team\n",
    "        self.game_id = game_id\n",
    "        self.turn_count = 0\n",
    "\n",
    "        self.last_event_indices: Dict[str, int] = {\n",
    "            \"blue_spymaster\": -1,\n",
    "            \"blue_operative\": -1,\n",
    "            \"red_spymaster\": -1,\n",
    "            \"red_operative\": -1,\n",
    "            \"game_engine\": -1,\n",
    "        }\n",
    "        self.game_events: List[Dict[str, str]] = []\n",
    "\n",
    "        self.game_ended_in_error: Dict[str, str] | None = None\n",
    "        self.game_ended_in_assassin = False\n",
    "        self.game_ended_in_turn_limit = False\n",
    "\n",
    "        self.all_words = DICTIONARY\n",
    "\n",
    "    # ───────── event log helpers ─────────\n",
    "    def log_event(self, role_key: str, description: str) -> None:\n",
    "        self.game_events.append({role_key: description})\n",
    "        self.last_event_indices[role_key] = len(self.game_events) - 1\n",
    "        if DEBUG:\n",
    "            print(f\"{role_key}: {description}\")\n",
    "\n",
    "    def format_events_for_player(self, role_key: str) -> str:\n",
    "        last_seen = self.last_event_indices.get(role_key, -1)\n",
    "        new_events = self.game_events[last_seen + 1 :]\n",
    "        if not new_events:\n",
    "            return \"\"\n",
    "        lines = [\"--- events since your last turn ---\"]\n",
    "        for ev in new_events:\n",
    "            for rk, desc in ev.items():\n",
    "                lines.append(f\"{rk}: {desc}\")\n",
    "        lines.append(\"----------------------------------\")\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "    # ───────── board helpers ─────────\n",
    "    def reveal_card(self, card: Card) -> str | None:\n",
    "        if card.revealed:\n",
    "            return None\n",
    "        card.revealed = True\n",
    "        if card.color in (\"blue\", \"red\"):\n",
    "            self.words_left[card.color] -= 1\n",
    "        return card.color\n",
    "\n",
    "    def get_unrevealed_cards(self) -> List[Card]:\n",
    "        return [c for c in self.cards if not c.revealed]\n",
    "\n",
    "    def get_revealed_cards(self) -> List[Card]:\n",
    "        return [c for c in self.cards if c.revealed]\n",
    "\n",
    "    # ───────── rules / win conditions ─────────\n",
    "    def check_end_game(self) -> Tuple[str | None, str | None]:\n",
    "        # assassin?\n",
    "        if any(c for c in self.cards if c.color == \"assassin\" and c.revealed):\n",
    "            loser = self.current_team\n",
    "            winner = \"red\" if loser == \"blue\" else \"blue\"\n",
    "            self.game_ended_in_assassin = True\n",
    "            return winner, f\"{loser} revealed the assassin\"\n",
    "        # all words guessed?\n",
    "        if self.words_left[\"blue\"] == 0:\n",
    "            return \"blue\", \"Blue found all their words\"\n",
    "        if self.words_left[\"red\"] == 0:\n",
    "            return \"red\", \"Red found all their words\"\n",
    "        return None, None\n",
    "\n",
    "    def switch_turn(self) -> None:\n",
    "        self.current_team = \"red\" if self.current_team == \"blue\" else \"blue\"\n",
    "\n",
    "    def follows_clue_rules(self, clue_word: str) -> bool:\n",
    "        # single token\n",
    "        if len(clue_word.split()) > 1:\n",
    "            return False\n",
    "        # letters / hyphens only\n",
    "        if re.search(r\"[^A-Za-z\\-]\", clue_word):\n",
    "            return False\n",
    "        # cannot be an unrevealed board word\n",
    "        if clue_word.lower() in {c.word.lower() for c in self.get_unrevealed_cards()}:\n",
    "            return False\n",
    "        # must be in dictionary\n",
    "        if clue_word.lower() not in self.all_words:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "\n",
    "def create_operative_feedback(max_guesses, guesses_taken, guess, color, outcome):\n",
    "    operative_feedback = \"\"\n",
    "    if outcome.startswith(\"correct\"):\n",
    "        operative_feedback = (\n",
    "            f\"Your guess '{guess}' was correct! It belongs to your team ({color}).\"\n",
    "        )\n",
    "        if guesses_taken >= max_guesses:\n",
    "            operative_feedback += f\" Max guesses reached ({max_guesses}), ending turn.\"\n",
    "        else:\n",
    "            operative_feedback += \" Either provide your next guess from the unrevealed cards on the board, or say end_turn.\"\n",
    "    elif outcome == \"neutral\":\n",
    "        operative_feedback = f\"Your guess '{guess}' was neutral. Your turn ends here.\"\n",
    "    elif outcome.startswith(\"other_team\"):\n",
    "        operative_feedback = f\"Your guess '{guess}' belongs to the other team ({color}). Your turn ends here.\"\n",
    "    return operative_feedback\n",
    "\n",
    "\n",
    "# ───────────────────────  3. Game orchestration  ──────────────────────────\n",
    "def create_game(\n",
    "    num_words: int = 25,\n",
    "    blue_count: int = 9,\n",
    "    red_count: int = 8,\n",
    "    assassin_count: int = 1,\n",
    "    neutral_count: int = 7,\n",
    "    starting_team: str = \"blue\",\n",
    "    game_id: int = 0,\n",
    ") -> GameState:\n",
    "    all_codenames_words = CODENAMES_WORDS\n",
    "    random.shuffle(all_codenames_words)\n",
    "    codenames_words = all_codenames_words[:num_words]\n",
    "\n",
    "    colors = (\n",
    "        [\"blue\"] * blue_count\n",
    "        + [\"red\"] * red_count\n",
    "        + [\"assassin\"] * assassin_count\n",
    "        + [\"neutral\"] * neutral_count\n",
    "    )\n",
    "    random.shuffle(colors)\n",
    "\n",
    "    cards = [Card(w, c) for w, c in zip(codenames_words, colors)]\n",
    "    return GameState(cards, starting_team, game_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uFUqDYgwjakD"
   },
   "outputs": [],
   "source": [
    "# ───────────────────────  LLM player classes  ──────────────────────────\n",
    "SPYMASTER_SYSTEM_PROMPT = \"\"\"You are a SPYMASTER in a game of Codenames.\n",
    "You are on a team (blue or red).\n",
    "You see which words belong to blue, red, neutral, and assassin.\n",
    "Your objective:\n",
    "- Give a ONE-WORD CLUE and a NUMBER, to guide your operative to guess your team's words.\n",
    "- Avoid giving a clue that makes your operative guess the assassin word, or else you lose immediately.\n",
    "- If the operative guesses a neutral or enemy word, the word is revealed and your turn ends, but the game continues.\n",
    "Strict format rules:\n",
    "- You must propose exactly one single-word clue\n",
    "- The clue must not be a word on the board\n",
    "- Your output must be in the format: clue_word, number (e.g. \"space, 2\")\n",
    "If you ever deviate from that exact output format, you lose.\n",
    "Please follow these instructions exactly.\"\"\"\n",
    "\n",
    "SPYMASTER_USER_PROMPT = \"\"\"Your turn. You are the {team} spymaster.\n",
    "Here is the current board (from your perspective), showing:\n",
    "  - which words are unrevealed (and their colors),\n",
    "  - which words are revealed (and their colors).\n",
    "You need to give a single-word clue and a number of words you want your operative to guess.\n",
    "\n",
    "{board}\n",
    "\n",
    "Please provide your ONE-WORD clue and a number, in the format: clue_word, number\"\"\"\n",
    "\n",
    "OPERATIVE_SYSTEM_PROMPT = \"\"\"You are an OPERATIVE in a game of Codenames.\n",
    "- Your spymaster gives you a ONE-WORD CLUE and a NUMBER.\n",
    "- You must guess words from the unrevealed board that match that clue.\n",
    "- You propose exactly ONE guess at a time, or say \"end_turn\" to stop guessing.\n",
    "- If you guess an enemy word or neutral word, your turn ends.\n",
    "- If you guess the assassin word, you immediately lose.\n",
    "- The clue's NUMBER is how many words the spymaster believes are related, but you can guess up to NUMBER + 1 (or fewer).\n",
    "Format rules:\n",
    "- Output must be either a single unrevealed word present on the board or \"end_turn\".\n",
    "- If you deviate from that, you lose.\"\"\"\n",
    "\n",
    "OPERATIVE_USER_PROMPT = \"\"\"Your turn. You are the {team} operative.\n",
    "Your spymaster's clue is: \"{clue}\" (number: {num}).\n",
    "Below is the board from your perspective:\n",
    "  - Which words are still unrevealed (without color info),\n",
    "  - Which words are revealed (with color).\n",
    "\n",
    "{board}\n",
    "\n",
    "Remember: Output exactly one guess word or 'end_turn'.\"\"\"\n",
    "\n",
    "\n",
    "class LLMSpymaster:\n",
    "    def __init__(\n",
    "        self,\n",
    "        team: str,\n",
    "        model: art.Model,\n",
    "        temperature: float = 0.7,\n",
    "        max_tokens: int = 20,\n",
    "    ):\n",
    "        self.team = team\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.conversation: List[Dict[str, str]] = [\n",
    "            {\"role\": \"system\", \"content\": SPYMASTER_SYSTEM_PROMPT}\n",
    "        ]\n",
    "        self.conversation_choices: List[dict] = []\n",
    "\n",
    "    def _board_summary(self, game_state):\n",
    "        unrevealed_cards = game_state.get_unrevealed_cards()\n",
    "        revealed_cards = game_state.get_revealed_cards()\n",
    "\n",
    "        lines = []\n",
    "        lines.append(f\"Number of words left for blue: {game_state.words_left['blue']}\")\n",
    "        lines.append(f\"Number of words left for red: {game_state.words_left['red']}\")\n",
    "        lines.append(\"UNREVEALED WORDS (and their colors):\")\n",
    "        # Group cards by color\n",
    "        # Group cards by color and add them in a specific order\n",
    "        for color in [\n",
    "            self.team,\n",
    "            \"red\" if self.team == \"blue\" else \"blue\",\n",
    "            \"neutral\",\n",
    "            \"assassin\",\n",
    "        ]:\n",
    "            for c in [c for c in unrevealed_cards if c.color == color]:\n",
    "                lines.append(f\"  {c.word} => {c.color}\")\n",
    "        lines.append(\"REVEALED WORDS (and their colors):\")\n",
    "        for c in revealed_cards:\n",
    "            lines.append(f\"  {c.word} => {c.color} (revealed)\")\n",
    "\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "    def _parse_clue(self, text: str, gs: GameState) -> Tuple[str, int]:\n",
    "        try:\n",
    "            cw, num = (s.strip() for s in text.split(\",\", 1))\n",
    "            num = int(num)\n",
    "        except Exception:\n",
    "            return \"invalid\", -1\n",
    "        if not gs.follows_clue_rules(cw):\n",
    "            return \"invalid\", -1\n",
    "        return cw, num\n",
    "\n",
    "    async def get_clue(self, gs: GameState, game_events: str) -> Tuple[str, int]:\n",
    "        if game_events:\n",
    "            self.conversation.append({\"role\": \"user\", \"content\": game_events})\n",
    "\n",
    "        prompt = SPYMASTER_USER_PROMPT.format(\n",
    "            team=self.team, board=self._board_summary(gs)\n",
    "        )\n",
    "        self.conversation.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "        resp = await call_llm(\n",
    "            self.model,\n",
    "            self.conversation,\n",
    "            self.temperature,\n",
    "            self.max_tokens,\n",
    "        )\n",
    "        self.conversation_choices.append(resp.choices[0])\n",
    "        text = resp.choices[0].message.content.strip()  # type: ignore\n",
    "        self.conversation.append({\"role\": \"assistant\", \"content\": text})\n",
    "\n",
    "        return self._parse_clue(text, gs)\n",
    "\n",
    "\n",
    "class LLMOperative:\n",
    "    def __init__(\n",
    "        self,\n",
    "        team: str,\n",
    "        model: art.Model,\n",
    "        temperature: float = 0.7,\n",
    "        max_tokens: int = 20,\n",
    "    ):\n",
    "        self.team = team\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.conversation: List[Dict[str, str]] = [\n",
    "            {\"role\": \"system\", \"content\": OPERATIVE_SYSTEM_PROMPT}\n",
    "        ]\n",
    "        self.conversation_choices: List[dict] = []\n",
    "        self.new_turn = True\n",
    "\n",
    "    def _board_summary(self, game_state: GameState):\n",
    "        \"\"\"\n",
    "        Build a summary from the operative's perspective:\n",
    "          - unrevealed words (no color info)\n",
    "          - revealed words (with color)\n",
    "        \"\"\"\n",
    "        unrevealed = game_state.get_unrevealed_cards()\n",
    "        revealed = game_state.get_revealed_cards()\n",
    "\n",
    "        lines = []\n",
    "        lines.append(f\"Number of words left for blue: {game_state.words_left['blue']}\")\n",
    "        lines.append(f\"Number of words left for red: {game_state.words_left['red']}\")\n",
    "        lines.append(\"UNREVEALED WORDS (no color info):\")\n",
    "        for c in unrevealed:\n",
    "            lines.append(f\"  {c.word}\")\n",
    "        lines.append(\"REVEALED WORDS (with color):\")\n",
    "        for c in revealed:\n",
    "            lines.append(f\"  {c.word}:{c.color}\")\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "    async def guess_word(\n",
    "        self,\n",
    "        gs: GameState,\n",
    "        clue_word: str,\n",
    "        clue_number: int,\n",
    "        game_events: str,\n",
    "    ) -> str:\n",
    "        if self.new_turn:\n",
    "            self.new_turn = False\n",
    "            if game_events:\n",
    "                self.conversation.append({\"role\": \"user\", \"content\": game_events})\n",
    "            prompt = OPERATIVE_USER_PROMPT.format(\n",
    "                team=self.team,\n",
    "                clue=clue_word,\n",
    "                num=clue_number,\n",
    "                board=self._board_summary(gs),\n",
    "            )\n",
    "            self.conversation.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "        resp = await call_llm(\n",
    "            self.model,\n",
    "            self.conversation,\n",
    "            self.temperature,\n",
    "            self.max_tokens,\n",
    "        )\n",
    "        self.conversation_choices.append(resp.choices[0])\n",
    "        guess = resp.choices[0].message.content.strip()  # type: ignore\n",
    "        self.conversation.append({\"role\": \"assistant\", \"content\": guess})\n",
    "        return guess\n",
    "\n",
    "    def start_new_turn(self):\n",
    "        self.new_turn = True\n",
    "\n",
    "    def add_guess_outcome(self, outcome: str):\n",
    "        self.conversation.append({\"role\": \"user\", \"content\": outcome})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x5zSJt3fwD0l"
   },
   "outputs": [],
   "source": [
    "# ───────────────────────  Gameplay  ──────────────────────────\n",
    "async def run_game(\n",
    "    gs: GameState,\n",
    "    blue_spy: LLMSpymaster,\n",
    "    blue_op: LLMOperative,\n",
    "    red_spy: LLMSpymaster,\n",
    "    red_op: LLMOperative,\n",
    ") -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Main loop – returns (winner, reason)\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        # turn limit\n",
    "        if gs.turn_count >= 50:\n",
    "            gs.game_ended_in_turn_limit = True\n",
    "            return \"No winner\", \"Turn limit reached\"\n",
    "\n",
    "        gs.turn_count += 1\n",
    "\n",
    "        # victory check\n",
    "        winner, reason = gs.check_end_game()\n",
    "        if winner:\n",
    "            gs.log_event(\"game_engine\", f\"GAME OVER: {reason}\")\n",
    "            return winner, reason\n",
    "\n",
    "        # who’s up?\n",
    "        team = gs.current_team\n",
    "        spy = blue_spy if team == \"blue\" else red_spy\n",
    "        op = blue_op if team == \"blue\" else red_op\n",
    "        spy_key = f\"{team}_spymaster\"\n",
    "        op_key = f\"{team}_operative\"\n",
    "\n",
    "        # ── Spymaster turn ──\n",
    "        spy_events = gs.format_events_for_player(spy_key)\n",
    "        clue_word, clue_num = await spy.get_clue(gs, spy_events)\n",
    "\n",
    "        if clue_word == \"invalid\" or clue_num < 0:\n",
    "            other = \"red\" if team == \"blue\" else \"blue\"\n",
    "            reason = f\"{team} gave invalid clue\"\n",
    "            gs.log_event(\"game_engine\", f\"GAME OVER: {other} wins – {reason}\")\n",
    "            gs.game_ended_in_error = {\"team\": team, \"role\": \"spymaster\"}\n",
    "            return other, reason\n",
    "\n",
    "        gs.log_event(spy_key, f\"clue '{clue_word}', {clue_num}\")\n",
    "\n",
    "        # ── Operative guesses ──\n",
    "        max_guesses = clue_num + 1\n",
    "        guesses = 0\n",
    "        op.start_new_turn()\n",
    "\n",
    "        while guesses < max_guesses:\n",
    "            # check win before guess\n",
    "            winner, reason = gs.check_end_game()\n",
    "            if winner:\n",
    "                gs.log_event(\"game_engine\", f\"GAME OVER: {reason}\")\n",
    "                return winner, reason\n",
    "\n",
    "            op_events = gs.format_events_for_player(op_key)\n",
    "            guess = await op.guess_word(gs, clue_word, clue_num, op_events)\n",
    "\n",
    "            if guess.lower() == \"end_turn\":\n",
    "                if guesses == 0:\n",
    "                    other = \"red\" if team == \"blue\" else \"blue\"\n",
    "                    reason = f\"{team} ended turn on the first guess\"\n",
    "                    gs.log_event(\"game_engine\", f\"GAME OVER: {other} wins – {reason}\")\n",
    "                    gs.game_ended_in_error = {\"team\": team, \"role\": \"operative\"}\n",
    "                    return other, reason\n",
    "                gs.log_event(op_key, \"ended turn\")\n",
    "                break\n",
    "\n",
    "            # validate guess\n",
    "            card = next(\n",
    "                (\n",
    "                    c\n",
    "                    for c in gs.get_unrevealed_cards()\n",
    "                    if c.word.lower() == guess.lower()\n",
    "                ),\n",
    "                None,\n",
    "            )\n",
    "            if not card:\n",
    "                other = \"red\" if team == \"blue\" else \"blue\"\n",
    "                reason = f\"{team} operative guessed invalid word '{guess}'\"\n",
    "                gs.log_event(op_key, reason)\n",
    "                gs.log_event(\"game_engine\", f\"GAME OVER: {other} wins – {reason}\")\n",
    "                gs.game_ended_in_error = {\"team\": team, \"role\": \"operative\"}\n",
    "                return other, reason\n",
    "\n",
    "            color = gs.reveal_card(card)\n",
    "            guesses += 1\n",
    "            outcome = (\n",
    "                \"correct\"\n",
    "                if color == team\n",
    "                else \"assassin\"\n",
    "                if color == \"assassin\"\n",
    "                else \"other_team\"\n",
    "                if color in (\"blue\", \"red\")\n",
    "                else \"neutral\"\n",
    "            )\n",
    "            gs.log_event(op_key, f\"guessed '{guess}', outcome: {outcome}\")\n",
    "\n",
    "            # feedback for LLM memory\n",
    "            op_feedback = create_operative_feedback(\n",
    "                max_guesses, guesses, guess, color, outcome\n",
    "            )\n",
    "            op.add_guess_outcome(op_feedback)\n",
    "\n",
    "            # post‑guess win check / turn handling\n",
    "            if outcome == \"correct\":\n",
    "                winner, reason = gs.check_end_game()\n",
    "                if winner or guesses >= max_guesses:\n",
    "                    break\n",
    "                continue  # another guess\n",
    "            elif outcome == \"assassin\":\n",
    "                other = \"red\" if team == \"blue\" else \"blue\"\n",
    "                gs.game_ended_in_assassin = True\n",
    "                return other, f\"{team} revealed the assassin\"\n",
    "            else:\n",
    "                break  # neutral or other team ends turn\n",
    "\n",
    "        gs.switch_turn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VcCZwM3gq9V6"
   },
   "outputs": [],
   "source": [
    "# ────────────────────  5. RL / reward helpers  ────────────────────────────\n",
    "def create_mc(player: LLMSpymaster | LLMOperative) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Merge messages & choices into a single list for art.\n",
    "    \"\"\"\n",
    "    mc = []\n",
    "    choice_i = 0\n",
    "    for msg in player.conversation:\n",
    "        if msg[\"role\"] == \"assistant\":\n",
    "            mc.append(player.conversation_choices[choice_i])\n",
    "            choice_i += 1\n",
    "        else:\n",
    "            mc.append(msg)\n",
    "    return mc\n",
    "\n",
    "\n",
    "def create_margin_reward(\n",
    "    player: LLMSpymaster | LLMOperative,\n",
    "    role_key: str,\n",
    "    gs: GameState,\n",
    "    winning_color: str,\n",
    "    reason: str,\n",
    ") -> float:\n",
    "    num_start_words = 9 if player.team == \"blue\" else 8\n",
    "    reward = 0.0\n",
    "\n",
    "    if gs.game_ended_in_turn_limit:\n",
    "        reward += MARGIN_REWARD_DICT[\"turn_limit\"]\n",
    "        return reward\n",
    "    if (\n",
    "        gs.game_ended_in_error\n",
    "        and role_key\n",
    "        == f\"{gs.game_ended_in_error['team']}_{gs.game_ended_in_error['role']}\"\n",
    "    ):\n",
    "        reward += MARGIN_REWARD_DICT[\"error\"]\n",
    "\n",
    "    if gs.game_ended_in_assassin and player.team != winning_color:\n",
    "        reward += MARGIN_REWARD_DICT[\"assassin\"]\n",
    "\n",
    "    # proportion of own words guessed\n",
    "    reward += (\n",
    "        (num_start_words - gs.words_left[player.team])\n",
    "        / num_start_words\n",
    "        * MARGIN_REWARD_DICT[\"num_words_multiplier\"]\n",
    "    )\n",
    "\n",
    "    # margin\n",
    "    loser = \"red\" if winning_color == \"blue\" else \"blue\"\n",
    "    margin = gs.words_left[loser]\n",
    "    reward += (\n",
    "        margin\n",
    "        * MARGIN_REWARD_DICT[\"margin_multiplier\"]\n",
    "        * (1 if player.team == winning_color else -1)\n",
    "    )\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2v5YiKPwu9b"
   },
   "source": [
    "# Defining a rollout\n",
    "\n",
    "<a name=\"Rollout\"></a>\n",
    "\n",
    "In each training step, we start with NUM_GAMES_PER_STEP different Codenames boards (let's say 10).\n",
    "\n",
    "NUM_GAMES_PER_STEP = 10\n",
    "\n",
    "For every board, the model plays 20 complete self‑play games (rollouts).\n",
    "\n",
    "NUM_ROLLOUTS_PER_GAME = 20\n",
    "\n",
    "Each rollout produces four separate records of experience—one for every role in the game—so a single board yields 80 trajectories in total.\n",
    "\n",
    "trajectories_per_rollout = 4 (one each for red spymaster, red operative, blue spymaster, blue operative)\n",
    "\n",
    "trajectories_per_board = NUM_ROLLOUTS_PER_GAME _ trajectories_per_rollout = 20 _ 4 = 80\n",
    "\n",
    "All trajectories from the same board+color+role are grouped together into a trajectory group.\n",
    "\n",
    "trajectory_groups_per_board = trajectories_per_board / NUM_ROLLOUTS_PER_GAME = 80 / 20 = 4\n",
    "\n",
    "Across the NUM_GAMES_PER_STEP (10) boards, this gives us NUM_GAMES_PER_STEP _ trajectory_groups_per_board = 10 _ 4 = 40 trajectory groups that ART uses for training in that step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mevAhbxQwuR1"
   },
   "outputs": [],
   "source": [
    "# ───────────────────────  6. Rollout logic  ───────────────────────────────\n",
    "async def run_single_rollout(\n",
    "    game_state: GameState,\n",
    "    blue_model: art.Model,\n",
    "    red_model: art.Model,\n",
    "    rollout_id: int,\n",
    "    step: int,\n",
    ") -> Dict[str, Dict[str, art.Trajectory]] | Exception:\n",
    "    \"\"\"\n",
    "    Play one rollout, i.e. one game, return trajectories for every player.\n",
    "    For each rollout, we return four trajectories: red spymaster, red operative, blue spymaster, blue operative.\n",
    "    We conduct the game, caluclate the reward for each trajectory, report to OpenPipe, and return the trajectories.\n",
    "    \"\"\"\n",
    "    player_classes = {\"spymaster\": LLMSpymaster, \"operative\": LLMOperative}\n",
    "    player_dict: Dict[str, Dict[str, LLMSpymaster | LLMOperative]] = {\n",
    "        \"blue\": {\n",
    "            role: player_classes[role](team=\"blue\", model=blue_model)\n",
    "            for role in (\"spymaster\", \"operative\")\n",
    "        },\n",
    "        \"red\": {\n",
    "            role: player_classes[role](team=\"red\", model=red_model)\n",
    "            for role in (\"spymaster\", \"operative\")\n",
    "        },\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        winner, reason = await run_game(\n",
    "            gs=game_state,\n",
    "            blue_spy=player_dict[\"blue\"][\"spymaster\"],  # type: ignore\n",
    "            blue_op=player_dict[\"blue\"][\"operative\"],  # type: ignore\n",
    "            red_spy=player_dict[\"red\"][\"spymaster\"],  # type: ignore\n",
    "            red_op=player_dict[\"red\"][\"operative\"],  # type: ignore\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return e\n",
    "\n",
    "    # ── build art trajectories ──\n",
    "    game_metrics = {\n",
    "        \"ended_in_error\": 1 if game_state.game_ended_in_error else 0,\n",
    "        \"ended_in_assassin\": 1 if game_state.game_ended_in_assassin else 0,\n",
    "        \"ended_completely\": 0\n",
    "        if (game_state.game_ended_in_error or game_state.game_ended_in_assassin)\n",
    "        else 1,\n",
    "        \"total_turns\": game_state.turn_count,\n",
    "        \"total_words_left\": game_state.words_left[\"blue\"]\n",
    "        + game_state.words_left[\"red\"],\n",
    "        \"winning_color\": 1 if winner == \"blue\" else 0,\n",
    "    }\n",
    "\n",
    "    op_client = AsyncOpenPipe()\n",
    "    trajectory_dict: Dict[str, Dict[str, art.Trajectory]] = {}\n",
    "\n",
    "    for team in (\"blue\", \"red\"):\n",
    "        for role in (\"spymaster\", \"operative\"):\n",
    "            player = player_dict[team][role]\n",
    "            role_key = f\"{team}_{role}\"\n",
    "            # finish conversation with final message\n",
    "            events = game_state.format_events_for_player(role_key)\n",
    "            if events:\n",
    "                player.conversation.append({\"role\": \"user\", \"content\": events})\n",
    "            player.conversation.append(\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Game over. {winner} won. Reason: {reason}\",\n",
    "                }\n",
    "            )\n",
    "\n",
    "            reward = create_margin_reward(player, role_key, game_state, winner, reason)\n",
    "            mc = create_mc(player)\n",
    "            traj = art.Trajectory(\n",
    "                messages_and_choices=mc,\n",
    "                reward=reward,\n",
    "                metrics={\"reward\": reward, **game_metrics},\n",
    "            )\n",
    "            trajectory_dict.setdefault(team, {})[role] = traj\n",
    "\n",
    "            # report to OpenPipe for observability (best‑effort)\n",
    "            try:\n",
    "                await op_client.report(\n",
    "                    req_payload={\n",
    "                        \"model\": f\"{player.model.name}_{team}\",\n",
    "                        \"messages\": player.conversation,\n",
    "                        \"metadata\": {\n",
    "                            \"game_id\": game_state.game_id,\n",
    "                            \"rollout_id\": rollout_id,\n",
    "                            \"step\": step,\n",
    "                            \"role\": role,\n",
    "                            \"team\": team,\n",
    "                            \"num_turns\": game_state.turn_count,\n",
    "                            \"blue_words_left\": game_state.words_left[\"blue\"],\n",
    "                            \"red_words_left\": game_state.words_left[\"red\"],\n",
    "                            \"winning_color\": winner,\n",
    "                            \"game_end_reason\": reason[:1000],\n",
    "                            \"reward\": reward,\n",
    "                        },\n",
    "                    },\n",
    "                    resp_payload={\n",
    "                        \"id\": f\"chatcmpl-{uuid.uuid4()}\",\n",
    "                        \"object\": \"chat.completion\",\n",
    "                        \"created\": int(time.time()),\n",
    "                        \"model\": f\"{player.model.name}_{team}\",\n",
    "                        \"choices\": [\n",
    "                            {\n",
    "                                \"index\": 0,\n",
    "                                \"message\": {\"role\": \"assistant\", \"content\": \"dummy\"},\n",
    "                                \"finish_reason\": \"stop\",\n",
    "                            }\n",
    "                        ],\n",
    "                        \"usage\": {\n",
    "                            \"prompt_tokens\": 0,\n",
    "                            \"completion_tokens\": 0,\n",
    "                            \"total_tokens\": 0,\n",
    "                        },\n",
    "                    },\n",
    "                    status_code=200,\n",
    "                )\n",
    "            except Exception as e:\n",
    "                if DEBUG:\n",
    "                    print(f\"OpenPipe report failed: {e}\")\n",
    "\n",
    "    return trajectory_dict\n",
    "\n",
    "\n",
    "async def conduct_games(\n",
    "    blue_model: art.Model,\n",
    "    red_model: art.Model,\n",
    "    num_rollouts_per_game: int,\n",
    "    game_id: int,\n",
    "    step: int,\n",
    ") -> List[art.TrajectoryGroup]:\n",
    "    \"\"\"\n",
    "    Play *num_rollouts_per_game* games concurrently for a fixed board.\n",
    "    The fixed board provides the same starting state for each rollout.\n",
    "    \"\"\"\n",
    "    base_state = create_game(game_id=game_id)\n",
    "\n",
    "    rollout_results = await asyncio.gather(\n",
    "        *[\n",
    "            run_single_rollout(\n",
    "                game_state=copy.deepcopy(base_state),\n",
    "                blue_model=blue_model,\n",
    "                red_model=red_model,\n",
    "                rollout_id=rid,\n",
    "                step=step,\n",
    "            )\n",
    "            for rid in range(num_rollouts_per_game)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    groups: Dict[str, List[art.Trajectory]] = {}\n",
    "    for res in rollout_results:\n",
    "        if isinstance(res, Exception):\n",
    "            continue\n",
    "        for team in (\"blue\", \"red\"):\n",
    "            for role in (\"spymaster\", \"operative\"):\n",
    "                groups.setdefault(f\"{team}_{role}\", []).append(res[team][role])\n",
    "\n",
    "    return [art.TrajectoryGroup(trajs) for trajs in groups.values()]\n",
    "\n",
    "\n",
    "async def _run_single_validation_game(\n",
    "    game_id: int,\n",
    "    my_model: art.Model,\n",
    "    benchmark_model: art.Model,\n",
    "    step: int = 0,\n",
    ") -> art.Trajectory | Exception:\n",
    "    \"\"\"\n",
    "    Creates a single game of Codenames, alternating your model and the benchmark model\n",
    "    (e.g. GPT-4o) between Blue and Red. Returns a list of your model’s Trajectories only, with the reward\n",
    "    for each set to 1 if your model won, and 0 otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a fresh game state\n",
    "    game_state = create_game(game_id=game_id)\n",
    "\n",
    "    # Alternate which side your model takes\n",
    "    if game_id % 2 == 0:\n",
    "        my_team, _other_team = \"blue\", \"red\"\n",
    "        blue_model, red_model = my_model, benchmark_model\n",
    "    else:\n",
    "        my_team, _other_team = \"red\", \"blue\"\n",
    "        blue_model, red_model = benchmark_model, my_model\n",
    "\n",
    "    # Run a single rollout (one game) using your existing code\n",
    "    trajectory_dict = await run_single_rollout(\n",
    "        game_state=copy.deepcopy(game_state),\n",
    "        blue_model=blue_model,\n",
    "        red_model=red_model,\n",
    "        rollout_id=game_id,\n",
    "        step=step,\n",
    "    )\n",
    "\n",
    "    if isinstance(trajectory_dict, Exception):\n",
    "        return trajectory_dict\n",
    "\n",
    "    winning_color = (\n",
    "        \"blue\"\n",
    "        if trajectory_dict[\"blue\"][\"spymaster\"].metrics.get(\"winning_color\", \"\") == 1\n",
    "        else \"red\"\n",
    "    )\n",
    "\n",
    "    my_traj = trajectory_dict[my_team][\"spymaster\"]\n",
    "    my_traj_reward = 1.0 if my_team == winning_color else 0.0\n",
    "\n",
    "    # Overwrite the reward in the trajectory\n",
    "    my_traj.reward = my_traj_reward\n",
    "    my_traj.metrics[\"win_rate\"] = my_traj_reward\n",
    "    my_traj.metrics[\"reward\"] = my_traj_reward\n",
    "\n",
    "    return my_traj\n",
    "\n",
    "\n",
    "async def run_validation_games(\n",
    "    my_model: art.Model,\n",
    "    benchmark_model: art.Model,\n",
    "    num_validation_games: int = 50,\n",
    "    step: int = 0,\n",
    ") -> List[art.Trajectory]:\n",
    "    \"\"\"\n",
    "    Creates `num_validation_games` games of Codenames, concurrently running them via asyncio.gather,\n",
    "    alternating your model vs. benchmark model (e.g. GPT‑4o) between Blue and Red.\n",
    "\n",
    "    Returns a flat list of your model’s trajectories. Each trajectory has a reward of 1 if your\n",
    "    model’s team won, and 0 if it lost.\n",
    "    \"\"\"\n",
    "    tasks = [\n",
    "        _run_single_validation_game(\n",
    "            game_id=gid,\n",
    "            my_model=my_model,\n",
    "            benchmark_model=benchmark_model,\n",
    "            step=step,\n",
    "        )\n",
    "        for gid in range(num_validation_games)\n",
    "    ]\n",
    "\n",
    "    # Run all validation games concurrently\n",
    "    result_trajectories = await tqdm_asyncio.gather(\n",
    "        *tasks, desc=\"Running validation games\", total=num_validation_games\n",
    "    )\n",
    "\n",
    "    return [t for t in result_trajectories if not isinstance(t, Exception)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZmUukH_YQPgy"
   },
   "source": [
    "# Model and Training Loop\n",
    "\n",
    "<a name=\"Loop\"></a>\n",
    "\n",
    "First, we create a trainable model which gives ART a spec of the model we want to train.\n",
    "Next, we create a backend, which could be local or point to a remote server which has art installed.\n",
    "We then register the model with the backend, letting the backend know where we will be training the model.\n",
    "You then have an openai client for your model, which will automatically point to the latest version of the model under training.\n",
    "\n",
    "For the training loop, we conduct training games and every 5 steps, we conduct validation games against val benchmark model.\n",
    "For every training step, we gather the trajectory groups from each starting position, flatten into groups, and then train the model on these groups.\n",
    "\n",
    "We provide additional benchmaking code to see how the model performs over time when compared to off the shelf models like gpt-4.1-nano and gpt-4.1-mini.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KZIiZ1VkrEUy"
   },
   "outputs": [],
   "source": [
    "# ───────────────────────────  7. Creating the model  ───────────────────────────\n",
    "from art.local import LocalBackend\n",
    "\n",
    "model = art.TrainableModel(\n",
    "    name=MODEL_NAME,\n",
    "    project=\"codenames-rl\",\n",
    "    base_model=BASE_MODEL_NAME,\n",
    ")\n",
    "\n",
    "benchmark_model = art.Model(\n",
    "    name=VAL_BENCHMARK_MODEL,\n",
    "    project=\"codenames-rl\",\n",
    "    inference_model_name=VAL_BENCHMARK_MODEL,\n",
    "    inference_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    inference_base_url=\"https://api.openai.com/v1\",\n",
    ")\n",
    "\n",
    "backend = LocalBackend(path=\"./.art\")\n",
    "\n",
    "await model.register(backend)\n",
    "await benchmark_model.register(backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "8355b345cb4043fab70187e0834c0445",
      "cc7451176687483b97400c7d49569fc7",
      "a6d0dd5450264fac841816e78bf23977",
      "c95567c2cd29473ca0115680f259b617",
      "67a48dd7754b48dab7d00664d024cb17",
      "af6e7578b0c043dea73a571e3f075642",
      "38836bd92b584ac099881392a143ce20",
      "04240998205a47658259a831f22fbf5c",
      "8739b444aa4140e2a1825037d898b28a",
      "9f57c1d9e83246d6ba4d9986890a835e",
      "594677078bbd46c6aff711f6a48d2c5d",
      "08c4ce89e87b414587692ed4a92cea96",
      "0850d7e5f8094acaa788e70af094530f",
      "8838a4b178df47a4af06101c0bad979b",
      "15a1c588cb1d438ab84413230dc92eee",
      "63b6d0c0aeeb4a399f19c2e176dde672",
      "a521340db0aa4c9088e61749ed504822",
      "15e2863a88ac47c4a9e5c062fdec80da",
      "91cad398a18c4afba36fe37717750f57",
      "b57f6ee06f3b40368819d4c91d8ef251",
      "032b1b52efe042f0b2bdc112ff523a33",
      "3836d33a28dd45ddb8f26f737fdaa3be",
      "ab38e1a843644c2a972b259ed25b99dc",
      "84d8a28d8f914b809fb8babfe9e3e6c9",
      "62d176de5bc2459cb4916cf37f3eede3",
      "3747a563b67d41889be9921594f52711",
      "7b135ee0959f4e2d816d264388d1405a",
      "e0f6fe9b84b44c0f9fd66eb538d39429",
      "53aaacd0315741289bcc9c8d43957473",
      "9226308a2e64444989b496173c22097e",
      "69911aa3b1b8425485ccae46e827351b",
      "3b14369d7c0149fe9ab6dc1721943501",
      "a61459687ea44a04af659d30b9d7a0aa",
      "418bee99950f4949b0e29e85af4a69c5",
      "bc2acdc423254993bbca1b7e05ac3829",
      "ef924d626f29447b8cc44aa76f89b401",
      "8a86fd8743534551880b9b13a0ee8db0",
      "1d586c241dbe4fa88d58ee81da11e752",
      "453fb2cd4d0145dcb162a29e7a2b65d6",
      "c4803abdd78b4358966584bec741459f",
      "6d24d814c0fa4296a52bf8abda07fc09",
      "d938c238d954499eab1acbe66c862353",
      "dc14b787a14f4b96a5c968ea405f5f3e",
      "2a2eb1e2c4c94bba9f9da5583b111796",
      "8f96b67f3c3846b4aee9757e1511bcd5",
      "814d49670b704da68d41fc48434edfb4",
      "e48020bec9ef482886bb4f5e97ac14d0",
      "55c11af139034e169f7cbf74f18a42fb",
      "cb273ab5d5334abfb9a6f8c38398c5e6",
      "57420126f16b464782b986bed3c63667",
      "c7f0ae4230e44bf59af3ba8440677eb8",
      "49aeb550c90d4c3385eb81992234b99b",
      "21921f2696d347d9b0f48417a4b414d5",
      "aa4f74c34ae54276956c1be5bac6c70b",
      "2a5f6c7adfee4b0ab03d23f104070113",
      "fd232f5c0124429fad9da974c4d9706a",
      "44337484bc2e4a0493454bcc2e45ec8c",
      "db96b1e579034511a460be2e81699304",
      "811070eaeea14587bfc8b4f5a77ce7ca",
      "07d7139e51ea44ad959ceea28f5aebef",
      "dbf47a813d184d2e93bba96cadeb6e63",
      "57eb027ada184bdca2a6020b2263d70a"
     ]
    },
    "id": "v2ESllEqjpla",
    "outputId": "8d734ed0-81e5-41d5-bd3a-92142bb6ee82"
   },
   "outputs": [],
   "source": [
    "# ───────────────────────────  8. Training loop  ───────────────────────────\n",
    "for step in range(await model.get_step(), NUM_STEPS):\n",
    "    # Our model under training plays against itself and learns from the rewards for each trajectory\n",
    "    nested_groups = await tqdm_asyncio.gather(\n",
    "        *[\n",
    "            conduct_games(\n",
    "                blue_model=model,\n",
    "                red_model=model,\n",
    "                num_rollouts_per_game=NUM_ROLLOUTS_PER_GAME,\n",
    "                game_id=gid,\n",
    "                step=step,\n",
    "            )\n",
    "            for gid in range(NUM_GAMES_PER_STEP)\n",
    "        ],\n",
    "        total=NUM_GAMES_PER_STEP,\n",
    "        desc=f\"step {step}\",\n",
    "    )\n",
    "\n",
    "    if step % 5 == 0:\n",
    "        # We run validation games to evaluate the performance of our model against the benchmark model. Here, the reward is 1 if our model wins, and 0 otherwise.\n",
    "        val_groups = await run_validation_games(\n",
    "            my_model=model,\n",
    "            benchmark_model=benchmark_model,\n",
    "            num_validation_games=NUM_VALIDATION_GAMES,\n",
    "        )\n",
    "        await model.log(val_groups)\n",
    "\n",
    "    flat_groups: List[art.TrajectoryGroup] = [g for sub in nested_groups for g in sub]\n",
    "    await model.train(\n",
    "        trajectory_groups=flat_groups,\n",
    "        config=art.TrainConfig(learning_rate=LEARNING_RATE, beta=BETA),\n",
    "    )\n",
    "    await model.delete_checkpoints()\n",
    "    print(f\"✓ finished step {step}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vGh6yN4Jjplb",
    "outputId": "f263a266-4c8a-48d4-8843-c1021ca61fc5"
   },
   "outputs": [],
   "source": [
    "# ───────────────────────────  9. Benchmark model  ───────────────────────────\n",
    "# We will benchmark our model by comparing the win rates against the benchmark model with that of gpt-4.1-nano and gpt-4.1-mini.\n",
    "gpt_41_nano = art.Model(\n",
    "    name=\"gpt-4.1-nano\",\n",
    "    project=\"codenames-rl\",\n",
    "    inference_model_name=\"gpt-4.1-nano\",\n",
    "    inference_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    inference_base_url=\"https://api.openai.com/v1\",\n",
    ")\n",
    "gpt_41_mini = art.Model(\n",
    "    name=\"gpt-4.1-mini\",\n",
    "    project=\"codenames-rl\",\n",
    "    inference_model_name=\"gpt-4.1-mini\",\n",
    "    inference_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    inference_base_url=\"https://api.openai.com/v1\",\n",
    ")\n",
    "\n",
    "gpt_models = [gpt_41_nano, gpt_41_mini]\n",
    "\n",
    "for gpt_model in gpt_models:\n",
    "    await gpt_model.register(backend)\n",
    "    val_groups = await run_validation_games(\n",
    "        my_model=gpt_model,\n",
    "        benchmark_model=benchmark_model,\n",
    "        num_validation_games=NUM_VALIDATION_GAMES,\n",
    "    )\n",
    "    await gpt_model.log(val_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_NQIBAlajplb"
   },
   "outputs": [],
   "source": [
    "# ───────────────────────────  10. Plotting Utilities  ───────────────────────────\n",
    "import os\n",
    "\n",
    "from art.utils.benchmarking.load_trajectories import load_trajectories\n",
    "from art.utils.benchmarking.charts import training_progress_chart\n",
    "from art.utils.benchmarking.types import BenchmarkModelKey\n",
    "\n",
    "df = await load_trajectories(\n",
    "    project_name=\"codenames-rl\",\n",
    "    models=[MODEL_NAME, \"gpt-4.1-nano\", \"gpt-4.1-mini\"],\n",
    "    art_path=\"./.art\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 932
    },
    "id": "eFWWjkY5jplb",
    "outputId": "732cab7f-916d-4640-e7d5-953e6e645529"
   },
   "outputs": [],
   "source": [
    "# ───────────────────────────  11. Plotting Win Rate over Time  ───────────────────────────\n",
    "line_graph = training_progress_chart(\n",
    "    df,\n",
    "    \"win_rate\",\n",
    "    models=[\n",
    "        BenchmarkModelKey(MODEL_NAME, MODEL_NAME, \"val\"),\n",
    "        BenchmarkModelKey(\"gpt-4.1-nano\", \"GPT-4.1-nano\", \"val\"),\n",
    "        BenchmarkModelKey(\"gpt-4.1-mini\", \"GPT-4.1-mini\", \"val\"),\n",
    "    ],\n",
    "    title=\"Win Rate over Time\",\n",
    "    y_label=\"Win Rate\",\n",
    ")\n",
    "\n",
    "line_graph.savefig(\"win_rate_over_time.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7fdMxpKjakE"
   },
   "source": [
    "<div class=\"align-center\">\n",
    "<a href=\"https://github.com/openpipe/art\"><img src=\"https://github.com/openpipe/art/raw/main/assets/ART_pill.png\" height=\"50\"></a>\n",
    "<a href=\"https://discord.com/invite/dnseNZuQ\"><img src=\"https://github.com/openpipe/art/raw/main/assets/Discord_pill.png\" height=\"50\"></a>\n",
    "<a href=\"https://openpipe.ai/blog/art-e-mail-agent\"><img src=\"https://github.com/openpipe/art/raw/main/assets/ART_E_pill.png\" height=\"50\"></a>\n",
    "\n",
    "Questions? Join the Discord and ask away! For feature requests or to leave a star, visit our [GitHub](https://github.com/openpipe/art).\n",
    "\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
